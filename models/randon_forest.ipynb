{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-18T11:39:19.256053900Z",
     "start_time": "2023-10-18T11:39:19.229000200Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "tr_tr_new = joblib.load('../joblib/tr_tr_encoded.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T11:39:21.202693700Z",
     "start_time": "2023-10-18T11:39:20.996572600Z"
    }
   },
   "id": "6def78dd08700f45"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "te_tr_new = joblib.load('../joblib/te_tr_encoded.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T11:39:22.095484400Z",
     "start_time": "2023-10-18T11:39:21.916308500Z"
    }
   },
   "id": "d80121348349aeaf"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "tr_tr_new.fillna(tr_tr_new.median(), inplace=True)\n",
    "\n",
    "# Fill missing values with median for testing data\n",
    "te_tr_new.fillna(tr_tr_new.median(), inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T11:39:25.955632600Z",
     "start_time": "2023-10-18T11:39:23.046388Z"
    }
   },
   "id": "4a5b5aad0cbfeac1"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Splitting the dataset into features and target\n",
    "X = tr_tr_new.drop(columns=['isFraud'])\n",
    "y = tr_tr_new['isFraud']\n",
    "\n",
    "# Splitting the dataset into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T11:39:27.902828300Z",
     "start_time": "2023-10-18T11:39:26.456411600Z"
    }
   },
   "id": "84a458661e70e124"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteracion = 1\n",
      "Metric train = 0.51 - Metric validation = 0.50.\n",
      "Iteracion = 2\n",
      "Metric train = 0.55 - Metric validation = 0.54.\n",
      "Iteracion = 3\n",
      "Metric train = 0.51 - Metric validation = 0.50.\n",
      "Iteracion = 4\n",
      "Metric train = 0.55 - Metric validation = 0.54.\n",
      "Iteracion = 5\n",
      "Metric train = 0.51 - Metric validation = 0.51.\n",
      "Iteracion = 6\n",
      "Metric train = 0.55 - Metric validation = 0.55.\n",
      "Iteracion = 7\n",
      "Metric train = 0.51 - Metric validation = 0.51.\n",
      "Iteracion = 8\n",
      "Metric train = 0.55 - Metric validation = 0.55.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as model_constructor\n",
    "from sklearn.metrics import roc_auc_score as metric\n",
    "\n",
    "# Random Forest\n",
    "n_estimators_values = [500,1000]\n",
    "max_features_values = [12,14]\n",
    "max_samples_values = [200, 600]\n",
    "\n",
    "params_grid = {'max_features': max_features_values,\n",
    "              'n_estimators': n_estimators_values,\n",
    "               'max_samples': max_samples_values}\n",
    "\n",
    "num_iter = 1\n",
    "grid_results = pd.DataFrame(columns = ('max_features',\n",
    "                                       'n_estimators',\n",
    "                                       'max_samples',\n",
    "                                       'metric_train',\n",
    "                                       'metric_val'))\n",
    "\n",
    "for max_features in params_grid['max_features']:\n",
    "    for n_estimators in params_grid['n_estimators']:\n",
    "        for max_samples in params_grid['max_samples']:\n",
    "\n",
    "                        # Print trace\n",
    "                        print('Iteracion = ' + str(num_iter))\n",
    "\n",
    "                        # [3] Define model\n",
    "                        model = model_constructor(max_features = max_features,\n",
    "                                                  n_estimators = n_estimators,\n",
    "                                                  max_samples = max_samples,\n",
    "                                                  random_state = 0)\n",
    "\n",
    "                        # [4] Train model\n",
    "                        model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "                        # [5] Predict\n",
    "                        pred_train = model.predict(X_train) # predict!\n",
    "                        pred_val = model.predict(X_val) # predict!\n",
    "\n",
    "                        # [6] Compute metric\n",
    "                        metric_train = metric(y_train, pred_train)\n",
    "                        metric_val = metric(y_val, pred_val)\n",
    "\n",
    "                        # print error\n",
    "                        print('Metric train = %.2f - Metric validation = %.2f.'\n",
    "                              % (metric_train, metric_val))\n",
    "\n",
    "                        # Save iteration results\n",
    "                        grid_results.loc[num_iter]=[ max_features,\n",
    "                                                    n_estimators,\n",
    "                                                    max_samples,\n",
    "                                                 metric_train,\n",
    "                                                 metric_val]\n",
    "                        num_iter += 1\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T11:53:05.620402700Z",
     "start_time": "2023-10-18T11:46:57.514143400Z"
    }
   },
   "id": "bef4ccde77ddbb0d"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "max_features     12.000000\nn_estimators    500.000000\nmax_samples     600.000000\nmetric_train      0.549443\nmetric_val        0.543480\nName: 1, dtype: float64"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results = grid_results.sort_values(by = ['metric_val', 'metric_train'], ascending = [False, False])\n",
    "best_model = grid_results.iloc[0]\n",
    "best_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T11:46:37.165110100Z",
     "start_time": "2023-10-18T11:46:37.124205200Z"
    }
   },
   "id": "d8893cf9a69a2227"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print('Old train data size = ' + str(X_train.shape))\n",
    "print('Old train target size = ' + str(y_train.shape))\n",
    "\n",
    "# Combine train and validaci√≥n\n",
    "X_train = np.concatenate((X_train, X_val), axis = 0)\n",
    "y_train = np.concatenate((y_train, y_val), axis = 0)\n",
    "\n",
    "print('New train data size = ' + str(X_train.shape))\n",
    "print('New train target size = ' + str(y_train.shape))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8560a952ff0bc39"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# [3] Define model\n",
    "model = model_constructor(criterion = 'gini',\n",
    "                          max_depth = None,\n",
    "                          min_samples_split = 2,\n",
    "                          min_samples_leaf = 1,\n",
    "                          max_features = int(best_model.max_features),\n",
    "                          n_estimators =  int(best_model.n_estimators),\n",
    "                          max_samples = int(best_model.max_samples),\n",
    "                          random_state = 0) # Use same random_state as in training!!!\n",
    "\n",
    "# [4] Train model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# [5] Predict\n",
    "pred_train = model.predict(X_train)\n",
    "pred_test = model.predict(X_test)\n",
    "\n",
    "# [6] Compute metric\n",
    "metric_train = metric(y_train, pred_train)\n",
    "metric_test = metric(y_test, pred_test)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc60c39bcf77caa5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print error\n",
    "print('AUC train = %.2f - AUC test = %.2f'\n",
    "      % (metric_train, metric_test))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d36db2d790a675da"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
