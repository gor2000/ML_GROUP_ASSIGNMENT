{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import joblib\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T09:17:37.805170900Z",
     "start_time": "2023-10-18T09:17:35.334418200Z"
    }
   },
   "id": "dca14a5dd5c7d4de"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "# Load the dataset\n",
    "tr_tr_new = joblib.load('../joblib/tr_tr_encoded.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T09:17:41.359963200Z",
     "start_time": "2023-10-18T09:17:39.303148300Z"
    }
   },
   "id": "af78a6945e241c10"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "te_tr_new = joblib.load('../joblib/te_tr_encoded.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T09:29:09.790180700Z",
     "start_time": "2023-10-18T09:29:08.088531900Z"
    }
   },
   "id": "d2a88328c24b406b"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Splitting the dataset into features and target\n",
    "X = tr_tr_new.drop(columns=['isFraud'])\n",
    "y = tr_tr_new['isFraud']\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T09:17:44.519156100Z",
     "start_time": "2023-10-18T09:17:42.832451700Z"
    }
   },
   "id": "fb021bc1da334644"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'objective':'binary',\n",
    "    'boosting_type':'gbdt',\n",
    "    'metric':'auc',\n",
    "    'n_jobs':-1,\n",
    "    'learning_rate':0.007,\n",
    "    'num_leaves': 2**8,\n",
    "    'max_depth':-1,\n",
    "    'tree_learner':'serial',        # Change here\n",
    "    'colsample_bytree': 0.5,\n",
    "    'subsample_freq':1,\n",
    "    'subsample':0.7,\n",
    "    'n_estimators':10000,\n",
    "    'max_bin':255,\n",
    "    'verbose':-1,\n",
    "    'seed': 0,\n",
    "    'early_stopping_rounds':100,\n",
    "    'device_type': 'gpu'             # Add this line\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T09:40:37.072984400Z",
     "start_time": "2023-10-18T09:40:37.058886700Z"
    }
   },
   "id": "2b4ad7195f24a2bd"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# Create datasets for LightGBM\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T09:40:39.702989200Z",
     "start_time": "2023-10-18T09:40:39.674010Z"
    }
   },
   "id": "3503f4249f8781fa"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model = lgb.train(lgb_params,\n",
    "                  train_data,\n",
    "                  valid_sets=[train_data, valid_data])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T09:54:28.246703200Z",
     "start_time": "2023-10-18T09:40:41.554225700Z"
    }
   },
   "id": "ed20898ae2f0371d"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-18T09:59:26.989292500Z",
     "start_time": "2023-10-18T09:56:57.243415Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUC: 0.9763\n",
      "Metric train = 1.0000 - Metric val = 0.9763\n"
     ]
    }
   ],
   "source": [
    "# Predict scores on train, validation\n",
    "pred_train_p = model.predict(X_train)\n",
    "pred_val_p = model.predict(X_valid)\n",
    "# If you have a separate test set, uncomment the line below\n",
    "# pred_test_p = model.predict(X_test)\n",
    "\n",
    "# Compute AUC\n",
    "auc_train = roc_auc_score(y_train, pred_train_p)\n",
    "auc_val = roc_auc_score(y_valid, pred_val_p)\n",
    "# If you have a separate test set, uncomment the line below\n",
    "# auc_test = roc_auc_score(y_test, pred_test_p)\n",
    "\n",
    "print(f\"Validation AUC: {auc_val:.4f}\")\n",
    "print('Metric train = %.4f - Metric val = %.4f' % (auc_train, auc_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pred_te_tr_new_p = model.predict(te_tr_new)\n",
    "\n",
    "# Create the output DataFrame\n",
    "output_df = pd.DataFrame({\n",
    "    'TransactionID': te_tr_new.reset_index()['TransactionID'],\n",
    "    'isFraud': pred_te_tr_new_p\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_df.to_csv('predicted_fraud_lightgbm[4].csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T10:03:14.256558900Z",
     "start_time": "2023-10-18T10:01:12.032131300Z"
    }
   },
   "id": "4745618d59bcda6f"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [12:07:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0cec3277c4d9d0165-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [12:07:25] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0cec3277c4d9d0165-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming model_lgbm is your trained LightGBM model and model_xgb is your trained XGBoost model\n",
    "# And X_train, X_valid and y_train are your training and validation data\n",
    "\n",
    "# Get the predictions from both models for your training data\n",
    "train_preds_lgbm = model.predict(X_train)\n",
    "\n",
    "model_xgb = joblib.load('../models_libjob/xgboost_model[0.9728].joblib')\n",
    "train_preds_xgb = model_xgb.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Stack predictions together\n",
    "stacked_train_predictions = np.column_stack((train_preds_lgbm, train_preds_xgb))\n",
    "\n",
    "# Train a logistic regression model on the stacked predictions\n",
    "meta_model = LogisticRegression().fit(stacked_train_predictions, y_train)\n",
    "\n",
    "# Get predictions for test set (te_tr_new) and stack them\n",
    "test_preds_lgbm = model.predict(te_tr_new)\n",
    "test_preds_xgb = model_xgb.predict_proba(te_tr_new)[:, 1]\n",
    "stacked_test_predictions = np.column_stack((test_preds_lgbm, test_preds_xgb))\n",
    "\n",
    "# Make final predictions using the meta model\n",
    "final_preds = meta_model.predict_proba(stacked_test_predictions)[:, 1]\n",
    "\n",
    "# Create the output DataFrame\n",
    "output_df = pd.DataFrame({\n",
    "    'TransactionID': te_tr_new.reset_index()['TransactionID'],\n",
    "    'isFraud': final_preds\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_df.to_csv('stacked_predictions.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T10:11:23.938667300Z",
     "start_time": "2023-10-18T10:05:34.650399100Z"
    }
   },
   "id": "97c8ea71331ab201"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d52f63d08f30561f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Convert datasets to DMatrix for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train)\n",
    "dtest = xgb.DMatrix(te_tr_new)\n",
    "\n",
    "# LightGBM: Using predict() for probability scores\n",
    "train_preds_lgbm = model_lgbm.predict(X_train)\n",
    "test_preds_lgbm = model_lgbm.predict(te_tr_new)\n",
    "\n",
    "# XGBoost: Use DMatrix and then predict()\n",
    "train_preds_xgb = model_xgb.predict(dtrain)\n",
    "test_preds_xgb = model_xgb.predict(dtest)\n",
    "\n",
    "# Stack predictions together for train and test sets\n",
    "stacked_train_predictions = np.column_stack((train_preds_lgbm, train_preds_xgb))\n",
    "stacked_test_predictions = np.column_stack((test_preds_lgbm, test_preds_xgb))\n",
    "\n",
    "# Train a logistic regression model on the stacked predictions\n",
    "meta_model = LogisticRegression().fit(stacked_train_predictions, y_train)\n",
    "\n",
    "# Make final predictions using the meta model\n",
    "final_preds = meta_model.predict_proba(stacked_test_predictions)[:, 1]\n",
    "\n",
    "# Create the output DataFrame\n",
    "output_df = pd.DataFrame({\n",
    "    'TransactionID': te_tr_new.reset_index()['TransactionID'],\n",
    "    'isFraud': final_preds\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_df.to_csv('stacked_predictions.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2633b8805e591cef"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Convert datasets to DMatrix for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train)\n",
    "dtest = xgb.DMatrix(te_tr_new)\n",
    "\n",
    "# LightGBM: Using predict() for probability scores\n",
    "train_preds_lgbm = model.predict(X_train)\n",
    "test_preds_lgbm = model.predict(te_tr_new)\n",
    "\n",
    "# XGBoost: Use DMatrix and then predict()\n",
    "train_preds_xgb = model_xgb.predict(dtrain)\n",
    "test_preds_xgb = model_xgb.predict(dtest)\n",
    "\n",
    "# Stack predictions together for train and test sets\n",
    "stacked_train_predictions = np.column_stack((train_preds_lgbm, train_preds_xgb))\n",
    "stacked_test_predictions = np.column_stack((test_preds_lgbm, test_preds_xgb))\n",
    "\n",
    "# Train a logistic regression model on the stacked predictions\n",
    "meta_model = LogisticRegression().fit(stacked_train_predictions, y_train)\n",
    "\n",
    "# Make final predictions using the meta model\n",
    "final_preds = meta_model.predict_proba(stacked_test_predictions)[:, 1]\n",
    "\n",
    "# Create the output DataFrame\n",
    "output_df = pd.DataFrame({\n",
    "    'TransactionID': te_tr_new.reset_index()['TransactionID'],\n",
    "    'isFraud': final_preds\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_df.to_csv('stacked_predictions[1].csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c40f1707515a573"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
